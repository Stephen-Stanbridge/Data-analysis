{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\"> The goal of this model is to be able to recognize which painter of 50 artists painted certain painting.<br>\n",
    "Dataset used for training this model is taken from:<br>\n",
    " - https://www.kaggle.com/ikarus777/best-artworks-of-all-time?select=resized\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\"> After downloading dataset, categories had to be pulled from filenames because dataset wasn't grouped in appropriate directories. Thanks to repeatable schema of filenames the best way to do it was to use regex' search and group methods. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"resized/\"\n",
    "categories = []\n",
    "def get_categories():\n",
    "    for name in os.listdir(data_dir):\n",
    "        if not name.endswith('.jpg'):\n",
    "            continue\n",
    "        clean_name = re.search('(.*)_\\d*.jpg', name)\n",
    "        categories.append(clean_name.group(1))  \n",
    "    return set(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\"> In order to get best possible outcome of model's predictions, images in dataset had to be of the same size.<br>\n",
    "    CV2 library is used below in order to get images' arrays which simply are just arrays of pixels that create certain image.<br>\n",
    "    After resizing image it is assigned to its category.<br>\n",
    "    Categories are represented with numbers because numeric values are understood best by model.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 200\n",
    "pictures_set = []\n",
    "categories = list(get_categories())\n",
    "for name in os.listdir(data_dir):\n",
    "    if not name.endswith('.jpg'):\n",
    "        continue\n",
    "    clean_name = re.search('(.*)_\\d*.jpg', name)\n",
    "    img_array = cv2.imread(os.path.join(data_dir, name))\n",
    "    resized_img_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "    pictures_set.append([resized_img_array, categories.index(clean_name.group(1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\"> Data should be shuffled in order to avoid any possible bias.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(pictures_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">Prepare X and y sets for training and testing model.<br>\n",
    "Reshape features set so it represents image and RGB values of pixels.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for feature, category in pictures_set:\n",
    "    X.append(feature)\n",
    "    y.append(category)\n",
    "\n",
    "X = np.asarray(X).reshape(-1,IMG_SIZE, IMG_SIZE, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\"> Divide X and y sets for training and testing (validation) data. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6684 1671 6684 1671\n"
     ]
    }
   ],
   "source": [
    "dataset_length = len(X)\n",
    "X_train = X[:int(dataset_length*0.8)]\n",
    "X_test = X[int(dataset_length*0.8):]\n",
    "y_train = y[:int(dataset_length*0.8)]\n",
    "y_test = y[int(dataset_length*0.8):]\n",
    "print(\n",
    "    len(X_train),\n",
    "    len(X_test),\n",
    "    len(y_train),\n",
    "    len(y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\"> Scale pixels' values so they will be standarized amongst all data.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\"> Convert categories to binary matrix so they can be used in categorical crossentropy loss function. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "class_num = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\"> Save feature set and category (class) set with pickle dump so it can be reused later on. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "X_file = open('.X.pickle', 'wb')\n",
    "pickle.dump(X, X_file)\n",
    "X_file.close()\n",
    "\n",
    "y_file = open('.y.pickle', 'wb')\n",
    "pickle.dump(y, y_file)\n",
    "y_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.constraints import maxnorm\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\"> I chose Sequential model blueprint which is appropriate for a stack of layers where each layer has exactly one input tensor and one output tensor. It is one of most commonly used blueprints.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">Conv2D is convolutional layer which is a class of deep neural networks, usually it is applied to analyzing visual imagery.\n",
    "Arguments of this layer:\n",
    "- 32 - number of filters. Filter is what neural network uses to form a representation of the image,\n",
    "- (3, 3) - size of filter,\n",
    "- input_shape - shape of input that will go to convolutional layer (and progress further through layers),\n",
    "- padding - 'same' argument defines that images will not be resized.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32, (3, 3), input_shape=X_train.shape[1:], padding='same'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">\n",
    "    <ul>\n",
    " <li> Activation - Activation function / layer. Values that represent certain image are forwarded to activation layer which reduces linearity of this data.</li>\n",
    " <li> Dropout - Dropout layer is used for preventing overfitting of a model. It drops random connections between layers.</li>\n",
    " <li> BatchNormalization - It normalizes input that goes into next layer in order to preserve distribution.</li>\n",
    " <li> MaxPooling2D - Pooling function is a function that takes information about image and compress it. It makes network more efficient at recognizing images based on the relevant features. Max pooling function takes, as name suggests, maximum values of pixels in a filter. It drops a lot of useless information.</li>\n",
    " <li> Flatten - Final layers of convolutional neural network have to be in form of vector. This function makes them as such.</li>\n",
    " <li> Dense -  Dense function's aim is to analyze the input features and combine them into different attributes that will help in classification. These layers are collections of neurons that represent different parts of the image.</li>\n",
    "    </ul>\n",
    "\n",
    "After specyfing those layers i compile model with 'adam' optimizer which is algorithm that reduces loss by tuning weights appropriately.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(class_num))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">After compilation of model it can be trained on prepared sets. Arguments:\n",
    " - epochs - number of passes of the entire training dataset,\n",
    " - batch_size - number of training examples utilized in one iteration.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "209/209 [==============================] - 368s 2s/step - loss: 18.6956 - accuracy: 0.1457 - val_loss: 258.9274 - val_accuracy: 0.0413\n",
      "Epoch 2/2\n",
      "209/209 [==============================] - 379s 2s/step - loss: 15.0101 - accuracy: 0.3475 - val_loss: 224.5051 - val_accuracy: 0.0048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcbfc4fe070>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\"> I've only used two epochs because training a model is a very demanding process for GPU and it can take quite a long time. Still, after only two epochs we get almost 50% of accuracy in recognizing paintings from 50 categories.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4787552170455456"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[1]*100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
